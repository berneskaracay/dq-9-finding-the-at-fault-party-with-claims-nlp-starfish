---
jupyter:
  jupytext:
    formats: ipynb,Rmd
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.0'
      jupytext_version: 1.0.5
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

```{python}
#######################################
print('Setting everything up...')
#######################################

import warnings
warnings.filterwarnings('ignore')

import pandas as pd
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.lines as mlines
from matplotlib.lines import Line2D

import matplotlib.ticker as ticker
import matplotlib.cm as cm
import matplotlib as mpl

import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
import nltk
nltk.download('punkt')
nltk.download('stopwords')
import os
import sys
import mysql.connector
from datetime import datetime
from datetime import date
from datetime import time
from datetime import timedelta
from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator

import seaborn as sns
plt.style.use('ggplot')
pd.options.display.max_rows = 999
pd.options.display.max_columns = 100
pd.options.display.max_colwidth = 100
import spacy


import nltk
from nltk import word_tokenize
from nltk.corpus import stopwords
# stop = stopwords.words('english')
nlp = spacy.load('en_core_web_sm')

from IPython.display import HTML as html_print

def cstr(s, color='black'):
    return "<text style=color:{}>{}</text>".format(color, s)


print('done.')

```

```{python}
general_data = pd.read_csv("data/NSS_DS_data.thegeneral.csv")
```

```{python}
general_data.shape
```

```{python}

general_data.describe(include='all')
```

```{python}
general_data.info()
```

```{python}
general_data.isnull().sum(axis = 0)



```

```{python}
general_data.head()
```

```{python}
general_data.nunique()
```

```{python}
general_data.groupby('ClaimGroup').count()
```

```{python}
general_data.groupby('SeverityTypeName').count()
```

```{python}
general_data["AccidentDescription"].head()
```

```{python}

general_data["ClaimLevelBody"][2]
```

```{python}
general_data["ExposureLevelBody"][2]
```

```{python}
general_data['FaultRatingName'].value_counts().plot.bar(title="Freq dist of Fault Rating")
```

```{python}
general_data.AccidentDescription=general_data.AccidentDescription.str.replace('Â½ ', "")

general_data.AccidentDescription=general_data.AccidentDescription.str.replace('*', "")

general_data['AccidentDescription'].str.lower().str.split().head()

stop = stopwords.words('english')
general_data['AccidentDescription'] = general_data['AccidentDescription'].apply(lambda x: " ".join(x for x in x.split() if x not in stop))
general_data.head()

general_data['AccidentDescription'] = general_data['AccidentDescription'].str.replace('[^\w\s]','')


def custom_tokenize(text):
    if not text:
        print('Not text')
        text = ''
    return word_tokenize(text)
general_data['AccidentDescription'] = general_data.AccidentDescription.apply(custom_tokenize)


from collections import defaultdict
for source in general_data:
    word_freq = defaultdict(int)
    for text in general_data.AccidentDescription:
        for word in text:
            word_freq[word] += 1 

df_dict=pd.DataFrame.from_dict(word_freq, orient='index').sort_values(0, ascending=False).reset_index().rename(columns={'index': 'AccidentDescription',0: 'Frequency'})


df_dict.head(1)
```

```{python}
myData=df_dict.head(300)
```

```{python}
myData
```

```{python}
text=""
for index, row in myData.iterrows():
    str1=""
    str1= (row['AccidentDescription']+" ")*row['Frequency']
    text=text+str1
```

```{python}
text[:100]
```

```{python}

wordcloud = WordCloud(max_font_size=100, max_words=100, background_color="white", collocations = False).generate(text)
plt.figure(figsize=(40,40))
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis("off")
plt.show()
```

```{python}
# #!pip install wordcloud
```

```{python}

```

```{python}

```

```{python}

```
